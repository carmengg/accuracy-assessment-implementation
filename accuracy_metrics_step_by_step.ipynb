{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "This is a Python notebook for calculating the following statistics in a land classification map:\n",
    "- producer's accuracies and user's accuracies by class,\n",
    "- overall accuracy, and\n",
    "- area estimates. \n",
    "\n",
    "Each statistic is accompanied by a 95% confidence interval. \n",
    "To do this, we follow the notation and calculations in Olofsson et al., 2014. \n",
    "\n",
    "The notebook uses the following inputs:\n",
    "\n",
    "1. A CSV file of the sampled points used for the accuracy assessment (each point is a row) with two columns: `map_class` and `ref_class`. The `map_class` column is the classification of a given point in the map, while `ref_class` is the \"ground truth\" classification of the point. \n",
    "\n",
    "2. A CSV file with the number of pixels per class in the map.\n",
    "\n",
    "3. The side length of a pixel in meters. \n",
    "\n",
    "The sample files used in the notebook have the data used in Olofsson et al., 2014 to exemplify the good practices. \n",
    "\n",
    "## References\n",
    "\n",
    "Pontus Olofsson, Giles M. Foody, Martin Herold, Stephen V. Stehman, Curtis E. Woodcock, Michael A. Wulder, Good practices for estimating area and assessing accuracy of land change, Remote Sensing of Environment,Volume 148, 2014, Pages 42-57, ISSN 0034-4257, https://doi.org/10.1016/j.rse.2014.02.015.  (https://www.sciencedirect.com/science/article/pii/S0034425714000704)\n",
    "\n",
    "Perrot, M., & Duchesnay, É. (2011). Scikit-learn: Machine Learning in Python. Journal of\n",
    "Machine Learning Research, 12, 2825--2830."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "To run the example in Olofsson et al., do not import any data and do not execute the cells in this section. \n",
    "Instead, go to the next section and execute the cell having the Olofsson et al. data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load csv with validation points\n",
    "df = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                              'validation_data_salt13_p30_map',\n",
    "                              'salt13_p30_map_and_reference_classes.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load counts of pixels per class in map\n",
    "pix_counts = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                                'validation_data_salt13_p30_map',\n",
    "                                                'salt13_p30_2020_combined_pixel_counts_total.csv'))\n",
    "pix_counts = pix_counts.to_numpy()[0]\n",
    "pix_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# counts by reference class\n",
    "print('Points in each reference class')\n",
    "print(np.unique(df.ref_class, return_counts=True), '\\n')\n",
    "\n",
    "# counts by map class: these should match the counts given by the stratified sample design\n",
    "print('Points in each map class')\n",
    "print(np.unique(df.map_class, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify number of classes in the map\n",
    "n_classes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Here we calculate a confusion matrix $n$ for the given points such that \n",
    "\n",
    "$n_{i,j}$ = number of points predicted as class $i$, known to be class $j$, \n",
    "\n",
    "which is equivalent to\n",
    "\n",
    "$n_{i,j}$ = number of points that have map class as $i$ and reference class $j$.\n",
    "\n",
    "To do this, we use the [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function from the scikit-learn Python package (Perrot & Duchesnay, 2011). \n",
    "The matrix $C$ obtained with `confusion_matrix` is such that\n",
    "\n",
    "$C_{i,j}$ = points known to belong to class $i$ and are predicted as class  $j$.\n",
    "\n",
    "However, the notation in the Olofsson et al. paper is \n",
    "\n",
    "$n_{i,j}$ = number of points predicted as class $i$, known to be class $j$, \n",
    "\n",
    "so we need to take the transpose of $C$ to match the notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CALCULATE CONFUSION MATRIX FOR IMPORTED DATA\n",
    "n = confusion_matrix(df.ref_class, df.map_class, labels=range(n_classes)).T\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 200000  150000 3200000 6450000]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 66,   0,   5,   4],\n",
       "       [  0,  55,   8,  12],\n",
       "       [  1,   0, 153,  11],\n",
       "       [  2,   1,   9, 313]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USE EXAMPLE TO RUN NOTEBOOK\n",
    "\n",
    "# Olofsson et al. data - Table 8\n",
    "\n",
    "pix_counts = np.array([200000, 150000, 3200000, 6450000])\n",
    "print(pix_counts)\n",
    "\n",
    "n = np.array([\n",
    "    [66, 0,  5,   4],\n",
    "    [0,  55, 8,   12],\n",
    "    [1,  0,  153, 11],\n",
    "    [2,  1,  9,   313]])\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "Throughout the following, let \n",
    "- $q$ be the number of map classes, \n",
    "- $p_{ij}$ be the (true) fraction of the map that has map class $i$ and reference class $j$,\n",
    "- $p_{i\\cdot} = \\sum_{j=1}^q p_{ij}$ be the fraction of the map classified as class $i$, and\n",
    "- $p_{\\cdot j} = \\sum_{i=1}^q p_{ij}$ be the fraction of the class that has reference class $j$. \n",
    "\n",
    "### User's Accuracy\n",
    "The user's accuracy of class $i$ is the fraction of the area mapped as class $i$ that has reference class $i$.\n",
    "This can be calculated as (Olofsson et al., eq. 2):\n",
    "$$U_i = \\frac{p_{ii}}{p_{i\\cdot}}.$$\n",
    "This is equivalent to the *precision* of class $i$. For example, when there are two classes (positive and negative) the user's accuracy of the positive class is the same as the precision of the true class, TP/(TP + FP).\n",
    "\n",
    "Let $\\hat{U}_i$ be the estimate of $U_i$'s from the our sampled points. We have that\n",
    "$$\\hat{U}_i = \\frac{\\hat{p}_{ii}}{\\hat{p}_{i\\cdot}},$$\n",
    "where $\\hat{p}_{ij}$ are the estimations of $p_{ij}$ from the sample. \n",
    "For stratified random sampling in which the sampling strata correspond to the map classes we have that\n",
    "$$\\hat{p}_{ij} = W_i \\frac{n_{ij}}{n_{i\\cdot}},$$\n",
    "where\n",
    "- $W_i$ is the fraction of the map's area classified  as class $i$,\n",
    "- $n_{ij}$ is number of points with map class $i$, known to be reference class $j$ (entries in the confusion matrix), and\n",
    "- $n_{i\\cdot}$ is the number of points with map class $i$ (row sums in confusion matrix).\n",
    "\n",
    "Notice that the user's accuracy can be simplifeid to\n",
    "$$\\hat{U}_i = \\frac{n_{ii}}{n_{i\\cdot}}.$$\n",
    "This is the formula implemented in the code.\n",
    "\n",
    "For the user's accuracy of map class $i$, the estimated variance is (Olfosson et al., eq. 6):\n",
    "$$\\hat{V}(\\hat{U}_i) = \\frac{\\hat{U}_i (1-\\hat{U}_i)}{n_{i\\cdot}-1}.$$\n",
    "\n",
    "In this notbeokoj we calculate the user's accuracies first (before the overall accuracy) since these are needed to calculate the approximate variance of the overall accuracy. \n",
    "\n",
    "### Standard Error & Confidence Intervals\n",
    "The square root of the estimated variance results in the standard error of the estimator (Olofsson et al., sec. 4.3). \n",
    "For example, in the case of an estimated user's accuracy $\\hat{U}_i$ we have that $\\hat{S}(\\hat{U}_i) = \\sqrt{\\hat{V}(\\hat{U}_i)}$.\n",
    "\n",
    "The standard error is then used to get confidence intervals for the estimated statistic. The 95% confidence interval is estimated as (Olofsson et al., sec. 5.2.1)\n",
    "$$\\hat{U}_i \\pm 1.96 \\hat{S}(\\hat{U}_i) = \\hat{U}_i \\pm 1.96\\  \\sqrt{\\hat{V}(\\hat{U}_i)}.$$\n",
    "We can replace $\\hat{U}_i$ for the overall accuracy or producer's accuracy estimates to obtain the corresponding variances, standard errors, and confidence intervals. \n",
    "\n",
    "In the follwoing cells we will calculate $\\hat{U}_i$ with a 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's accuracies with 95% confidence interval\n",
      "class 1: 0.88 ± 0.07\n",
      "class 2: 0.73 ± 0.10\n",
      "class 3: 0.93 ± 0.04\n",
      "class 4: 0.96 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "# points in sample that had class i in map (predicted as i, any true class j)\n",
    "n_idot = [sum(n[i,:]) for i in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "# estimated user's accuracy\n",
    "U_hat = [n[i,i] / n_idot[i] for i in range(n_classes)]\n",
    "\n",
    "# variance of estimated user's accuracy\n",
    "var_U_hat = [U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "print(\"User's accuracies with 95% confidence interval\")\n",
    "for U_hati, var_i, i  in zip(U_hat, var_U_hat, range(n_classes)):\n",
    "    print(f'class {i+1}: {U_hati:.2f} ± {1.96 * np.sqrt(var_i):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Accuracy\n",
    "\n",
    "Let $O$ be the (true) accuracy of the map, and $\\hat{O}$ its estimation from the sample. Then, following Olofsson et al., section 4.3, we have that \n",
    "$$\\hat{O} = \\sum_{i=1}^q \\hat{p}_{ii} = \\sum_{i=1}^q W_i \\frac{n_{ii}}{n_{i\\cdot}}.$$\n",
    "Recall that $q$ is the number of classes in the map and $\\hat{p}_{ii}$ is the estimation of $p_{ii}$, the (true) fraction of the area in the map that was classified as class $i$ and has reference class $i$. \n",
    "\n",
    "For overall accuracy, the estimated variance is (Olofsson et al., eq. 5):\n",
    "$$\\hat{V}(\\hat{O}) = \\sum_{i=1}^q \\frac{W_i^2 \\hat{U}_i (1-\\hat{U}_i)}{n_{i\\cdot}-1}.$$\n",
    "\n",
    "In the follwoing cells we will calculate $\\hat{O}$ with a 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy with 95% confidence interval\"\n",
      "0.95 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "# total number of pixels in the map\n",
    "total_pix = sum(pix_counts)\n",
    "\n",
    "# fractions of area in map classified in each class\n",
    "W = [pix_counts[i]/ total_pix for i in range(n_classes)]      \n",
    "\n",
    "# -------------------------------------\n",
    "# estimated overall accuracy\n",
    "O_hat = sum([W[i]*n[i,i]/n_idot[i] for i in range(n_classes)])\n",
    "\n",
    "# -------------------------------------\n",
    "# variance of estimated overall accuracy\n",
    "var_O_hat = sum([ W[i]**2 * U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(n_classes)])\n",
    "\n",
    "# -------------------------------------\n",
    "print('Overall accuracy with 95% confidence interval')\n",
    "print(f'{O_hat:.2f} ± {1.96 * np.sqrt(var_O_hat):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producer's Accuracy\n",
    "The producer's accuracy of class $i$ is the fraction of the (true) area with reference class $i$ that is actually mapped as class $j$. \n",
    "We can calculate it as (Olofsson et al., eq. 3):\n",
    "$$P_j = \\frac{p_{jj}}{p_{\\cdot j}}.$$\n",
    "This is equivalent to the sensitiviy of class $j$. For example, when there are two classes (positive and negative) the producer's accuracy of the positive class is the same as the sensitivy of the true class (TP/(TP + FN)).\n",
    "\n",
    "The estimate of $P_j$ from the sampled points is\n",
    "$$\\hat{P}_j = \\frac{\\hat{p}_{jj}}{\\hat{p}_{\\cdot j}},$$\n",
    "where the $\\hat{p}_{ij}$ are as before.\n",
    "\n",
    "The estimated variance of the estimated producer's accuracy of class $j$ is given by (Olofsson et al., eq. 7):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{V}(\\hat{P}_j) = \n",
    "\\frac{1}{\\hat{N}_{\\cdot j}^2} \n",
    "\\left( \n",
    "\\frac{N_{j \\cdot}^2 (1 - \\hat{P}_j)^2 \\hat{U}_j (1-\\hat{U}_j)}{n_{j \\cdot} -1}  \n",
    "+\n",
    "\\hat{P}_j^2\n",
    "\\sum_{i\\neq j}^q \n",
    "\\frac{N_{i\\cdot}^2}{n_{i \\cdot} - 1} \n",
    "\\frac{n_{ij}}{n_{i \\cdot}} \n",
    "\\left( 1 - \\frac{n_{ij}}{n_{i \\cdot}} \\right)\n",
    "\\right),$$\n",
    "where\n",
    "- $N_{j \\cdot}$ is the number of pixels in the map with map class $j$,\n",
    "- $n_{j\\cdot}$ is the number of sample points with map class $j$, and\n",
    "- $\\hat{N}_{\\cdot j} = \\sum_{i=1}^q \\frac{N_{i\\cdot}}{n_{i\\cdot}}n_{ij}$ is the estimated number of pixels with reference class $j$.\n",
    "\n",
    "In the following cells we calculate $\\hat{P}_j$ with a 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producer's accuracies: [74.86614048308412, 84.71563981042654, 93.45089085796926, 96.16089928314558]\n",
      "producer's accuracies confidence interval: [21.22215374 25.31103589  3.41492981  1.82678542] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_hat_dotj = []\n",
    "# estimated producer's accuracy (sensitiviy for each class TP/(TP+FN))\n",
    "P_hat = []  \n",
    "\n",
    "for j in range(n_classes):\n",
    "    # list of p_hat_ij with fixed j\n",
    "    p_hat_ij = [ W[i]*n[i,j]/n_idot[i] for i in range(n_classes) ]\n",
    "    p_hat_dotj.append(sum(p_hat_ij))  # equation (9)\n",
    "\n",
    "\n",
    "P_hat= [ (W[j]*n[j,j]/n_idot[j]) / p_hat_dotj[j] for j in range(n_classes)]\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies:\", [x*100 for x in P_hat])\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "# VARIANCE\n",
    "# notice N_jdot is pixel_counts[j]\n",
    "N_hat_cdotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ pix_counts[i] * n[i,j]/n_idot[i] for i in range(n_classes)]\n",
    "    N_hat_cdotj.append(sum(summands))\n",
    "\n",
    "# -------------------------------------\n",
    "summand1 = [ (pix_counts[j]**2) * ((1-P_hat[j])**2) * U_hat[j] * (1-U_hat[j]) / (n_idot[j] - 1) \n",
    "            for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "summand2 = []\n",
    "for j in range(n_classes):\n",
    "    inner = []\n",
    "    for i in range(n_classes):\n",
    "        if i!=j:\n",
    "            inner.append( (pix_counts[i]**2) /(n_idot[i]-1) * (n[i,j])/(n_idot[i]) * ( 1 - n[i,j]/n_idot[i]) ) \n",
    "    summand2.append((P_hat[j]**2) * sum(inner))\n",
    "\n",
    "# -------------------------------------\n",
    "var_P_hat = [1/(N_hat_cdotj[j]**2) *  (summand1[j] + summand2[j]) for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies confidence interval:\", 1.95*np.sqrt(var_P_hat)*100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stratified random sampling when the map classes are the strata, we have that an estimator of the proportion of area of class $j$ is (Olofsson et al. eq. 9):\n",
    "$$ \\hat{p}_{\\cdot j} = \\sum_{i=1}^q W_i \\frac{n_{ij}}{n_{i\\cdot}}.$$\n",
    "\n",
    "For this estimator of area proportion per class, the standard error is estimated by (Olofsson et al. eq 10):\n",
    "$$S(\\hat{p}_{\\cdot j}) =  \n",
    "\\sqrt{\n",
    "\\sum_{i=1}^q W_i^2 \\frac{ \\frac{n_{ij}}{n_{i\\cdot}} \\left(1 -  \\frac{n_{ij}}{n_{i\\cdot}} \\right)}{n_{i \\cdot}-1}\n",
    "}.$$\n",
    "\n",
    "The estimated area of class $j$ is\n",
    "$$\\hat{A}_j = A \\times \\hat{p}_{\\cdot k},$$\n",
    "where $A$ is the total are of the map. \n",
    "The standard error for the area is given by (Olofsson et al. eq 11):\n",
    "$$ S(\\hat{A}_j) = A \\times S(\\hat{p}_{\\cdot j}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of area per class: \n",
      " [2.350862470862471, 1.2984615384615383, 31.752214452214456, 64.59846153846155]\n",
      "confidence interval for percentage area per class:\n",
      " [0.6841815984519081, 0.4173140028226505, 1.723315144243176, 1.8090729280271949]\n"
     ]
    }
   ],
   "source": [
    "# PERCENTAGE OF AREA ESTIMATION\n",
    "# we had calculated the area estimators before, they are used in producer's accuracy\n",
    "print(\"percentage of area per class: \\n\", [x*100 for x in p_hat_dotj])\n",
    "\n",
    "# -------------------------------------\n",
    "# STD ERROR\n",
    "SE_p_hat_dotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ (W[i]**2) * (n[i,j]/n_idot[i]) * (1 -  (n[i,j]/n_idot[i]))/ (n_idot[i]-1) \n",
    "                for i in range(n_classes)]\n",
    "    SE_p_hat_dotj.append(np.sqrt(sum(summands)))\n",
    "    \n",
    "print(\"confidence interval for percentage area per class:\\n\", [x*1.96*100 for x in SE_p_hat_dotj])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx area per class (ha): \n",
      " [21158.02223803551, 11686.297453174257, 285773.4417957486, 581393.2982954193]\n",
      "confidence interval for area per class (m^2):\n",
      " [6157.710055063028, 3755.8721794243975, 15510.026893093216, 16281.856431773647]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "map_area = total_pix * (21158/235086)\n",
    "\n",
    "approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"approx area per class (ha): \\n\", approx_area_per_class)\n",
    "\n",
    "SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"confidence interval for area per class (m^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # AREA ESTIMATION\n",
    "# # in m^2, assuming a resolution of 0.5m per pixel side\n",
    "# # (each pixel has an area of 0.25 m^2)\n",
    "# map_area = total_pix * 0.25 \n",
    "\n",
    "# approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "# print(\"approx area per class (m^2): \\n\", approx_area_per_class)\n",
    "\n",
    "# SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "# print(\"confidence interval for area per class (m^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # in km^2, assuming a resolution of 0.5m per pixel side\n",
    "# map_area = total_pix * 0.25 / (1000**2)\n",
    "\n",
    "# approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "# print(\"approx area per class (km^2): \\n\", approx_area_per_class)\n",
    "\n",
    "# SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "# print(\"confidence interval for area per class (km^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('mpc-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1dc46d330d73c1a34cd0818989dcb313f65702bd1fe31ebf50f6cafcea616860"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
